{"nbformat_minor": 1, "cells": [{"source": "#from pyspark import SparkConf, SparkContext\n#sc = SparkContext.getOrCreate()", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 13}, {"source": "#from pyspark.mllib.regression import LabeledPoint, LinearRegressionWithSGD, LinearRegressionModel", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 14}, {"source": "#def parsePoint(line):\n#    values = [float(x) for x in line.replace(',', ' ').split(' ')]\n#    return LabeledPoint(values[0], values[1:])", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 15}, {"source": "import pixiedust", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 47}, {"source": "#df = pixiedust.sampleData(\"https://raw.githubusercontent.com/markwatsonatx/watson-ml-for-developers/master/data/house-prices.csv\")\n#display(df)\n#type(df)\n\n", "cell_type": "code", "metadata": {"pixiedust": {"displayParams": {"handlerId": "tableView"}}, "scrolled": false}, "outputs": [], "execution_count": 25}, {"source": "#df.printSchema()", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 26}, {"source": "\nimport ibmos2spark\n# @hidden_cell\ncredentials = {\n    'endpoint': 'https://s3-api.us-geo.objectstorage.service.networklayer.com',\n    'service_id': 'iam-ServiceId-05799f7f-1507-4fee-abcc-1eb83733287a',\n    'iam_service_endpoint': 'https://iam.bluemix.net/oidc/token',\n    'api_key': 'fNfyX-dNo1VW6KIgqewt2APl_FbC66SIGfHqRdtLj6ah'\n}\n\nconfiguration_name = 'os_d0438052eccb4591a48d39cad8f168b8_configs'\ncos = ibmos2spark.CloudObjectStorage(sc, credentials, configuration_name, 'bluemix_cos')\n\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.getOrCreate()\ndf_data_1 = spark.read\\\n  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n  .option('header', 'true')\\\n  .option('inferSchema','True')\\\n  .load(cos.url('customerdata.csv', 'callforcodebocsp-donotdelete-pr-762lyejmogakw0'))\ndf_data_1.take(5)", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "execute_result", "data": {"text/plain": "[Row(asset=20000, transfreq=20, credit=90, line=10000),\n Row(asset=50000, transfreq=40, credit=95, line=12500),\n Row(asset=100000, transfreq=50, credit=100, line=20000),\n Row(asset=200000, transfreq=80, credit=100, line=20000),\n Row(asset=200000, transfreq=80, credit=90, line=15000)]"}, "execution_count": 49, "metadata": {}}], "execution_count": 49}, {"source": "df_data_1.printSchema()", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "root\n |-- asset: integer (nullable = true)\n |-- transfreq: integer (nullable = true)\n |-- credit: integer (nullable = true)\n |-- line: integer (nullable = true)\n\n"}], "execution_count": 50}, {"source": "from pyspark.ml import Pipeline\nfrom pyspark.ml.regression import LinearRegression\nfrom pyspark.ml.feature import VectorAssembler", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 51}, {"source": "assembler = VectorAssembler(inputCols=['asset','transfreq','credit'],outputCol=\"features\")\nlr = LinearRegression(labelCol='line', featuresCol='features')\npipeline = Pipeline(stages=[assembler, lr])\nmodel = pipeline.fit(df_data_1)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 52}, {"source": "def get_prediction(asset, transfreq, credit):\n    request_df = spark.createDataFrame([(asset, transfreq, credit)], ['asset','transfreq','credit'])\n    response_df = model.transform(request_df)\n    return response_df", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 53}, {"source": "response = get_prediction(2400, 40, 0)\nresponse.show()", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "+-----+---------+------+-----------------+-----------------+\n|asset|transfreq|credit|         features|       prediction|\n+-----+---------+------+-----------------+-----------------+\n| 2400|       40|     0|[2400.0,40.0,0.0]|701.1477502557209|\n+-----+---------+------+-----------------+-----------------+\n\n"}], "execution_count": 57}, {"source": "import json\nimport requests\nimport urllib3", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 58}, {"source": "service_path = 'https://us-south.ml.cloud.ibm.com'\nusername = '067600af-cb6c-4d46-a370-7ee1cd794c5b'\npassword = 'd518afdc-99e1-4b88-be81-019940a77254'\ninstance_id = '6b50131c-e7e8-4e49-b836-93f2300392d9'\nmodel_name = 'Credit Rating Model'\ndeployment_name = 'Credit Rating Deployment'\n", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 59}, {"source": "from repository.mlrepositoryclient import MLRepositoryClient\nfrom repository.mlrepositoryartifact import MLRepositoryArtifact\nml_repository_client = MLRepositoryClient(service_path)\nml_repository_client.authorize(username, password)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 60}, {"source": "\n\npipeline_artifact = MLRepositoryArtifact(pipeline, name=\"pipeline\")\nmodel_artifact = MLRepositoryArtifact(model, training_data=df_data_1, name=model_name, pipeline_artifact=pipeline_artifact)\nsaved_model = ml_repository_client.models.save(model_artifact)\nmodel_id = saved_model.uid\n\n", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 61}, {"source": "headers = urllib3.util.make_headers(basic_auth='{}:{}'.format(username, password))\nurl = '{}/v3/identity/token'.format(service_path)\nresponse = requests.get(url, headers=headers)\nml_token = 'Bearer ' + json.loads(response.text).get('token')", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 62}, {"source": "deployment_url = service_path + \"/v3/wml_instances/\" + instance_id + \"/published_models/\" + model_id + \"/deployments/\"\ndeployment_header = {'Content-Type': 'application/json', 'Authorization': ml_token}\ndeployment_payload = {\"type\": \"online\", \"name\": deployment_name}\ndeployment_response = requests.post(deployment_url, json=deployment_payload, headers=deployment_header)\ndeployment_response.text\nscoring_url = json.loads(deployment_response.text).get('entity').get('scoring_url')\nscoring_url", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "execute_result", "data": {"text/plain": "'https://us-south.ml.cloud.ibm.com/v3/wml_instances/6b50131c-e7e8-4e49-b836-93f2300392d9/published_models/808c8790-b257-454f-a9d3-1a2208b73867/deployments/c2409c20-653e-4937-8ad0-d187d28a078a/online'"}, "execution_count": 70, "metadata": {}}], "execution_count": 70}, {"source": "def get_prediction_from_watson_ml(asset, transfreq, credit):\n    scoring_header = {'Content-Type': 'application/json', 'Authorization': ml_token}\n    scoring_payload = {'fields': ['asset','transfreq','credit'], 'values': [[asset, transfreq, credit]]}\n    scoring_response = requests.post(scoring_url, json=scoring_payload, headers=scoring_header)\n    return scoring_response.text", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 71}, {"source": "response = get_prediction_from_watson_ml(2400, 40, 90)\nprint(response)", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "{\n  \"fields\": [\"asset\", \"transfreq\", \"credit\", \"features\", \"prediction\"],\n  \"values\": [[2400, 40, 90, [2400.0, 40.0, 90.0], 19336.76802948064]]\n}\n"}], "execution_count": 72}, {"source": "", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}], "metadata": {"kernelspec": {"display_name": "Python 3.6 with Spark", "name": "python36", "language": "python3"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "3.6.8", "name": "python", "pygments_lexer": "ipython3", "file_extension": ".py", "codemirror_mode": {"version": 3, "name": "ipython"}}}, "nbformat": 4}